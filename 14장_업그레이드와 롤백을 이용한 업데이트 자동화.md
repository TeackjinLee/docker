# 14.1 도커를 사용한 애플리케이션 업그레이드 프로세스

도커 이미지는 믿을수 없을만큼 단순한 패키징 포맷이다. 배포 주기는 애플리케이션 버전을 제외하고도 최소한 다음 네가지 주기를 고려해야 한다.<br>
첫 번쨰는 의존 모듈 업데이트<br>
두 번째는 애플리케이션 코드를 컴파일하는 데 사용하는 SDK 업데이트<br>
세 번째는 애플리케이션이 동작하는 플랫폼의 업데이트<br>
네 번쨰는 운영체제 업데이트<br>
그림 14-1은 리눅스에서 동작하는 닷넷 코어 애플리케이션의 여섯가지 업데이트 주기를 정리한 것이다<br>
<br>

<img width="50%" src="https://github.com/user-attachments/assets/0e48e675-de25-445c-bd52-c30846c8d8e0" />

<br>
이번 장은 8장에서 다뤘던 무작위 숫자 애플리케이션을 소재로 10장에서 배운 오버라이드 컴포즈 파일을 이용해 이 과정을 체험해 보겠다.<br>
결과물은 애플리케이션 정의만이 포함된 깔끔한 코어 컴포즈 파일 하나와 업데이트를 정의한 추가 파일이 될 것이다.<br>
여러 개로 나뉜 컴포즈 파일은 스택 배포에 사용할 수 없다. 그러므로 먼저 오버라이드 파일을 하나의 컴포즈 파일로 병합하는 방법부터 알아보자.<br>
<br>

[실습] 먼저 무작위 숫자 애플리케이션의 첫 빌드를 배포하는 것부터 시작해 보자. 웹 서비스는 한 개 컨테이너, API 서비스는 여섯 개 레플리카로 실행한다.<br>
      컨테이너 상태를 통해 롤링 업데이트의 진행 과정을 알 수 있을 것이다. 도커 엔진은 스웜 모드로 전환한다. 그리고 컴포즈 파일을 병합하고 병합한 파일로 스택을 배포한다.<br>
<br>

> cd ch14/exercises<br>
> 코어 컴포즈 파일과 오버라이드 파일을 병합한다.<br>
> docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml config > stack.yml<br>
> 병합된 컴포즈 파일로 스택을 배포한다.<br>
> docker stack deploy -c stack.yml numbers<br>
> docker stack services numbers<br>

<br>

![image](https://github.com/user-attachments/assets/821d4e41-4fc3-4cc4-b21b-ff8f680250db)

<br>
그림 14-2를 보면 스택에 대해 우리가 아직 배우지 않은 내용이 있다. API 서비스는 일반적인 replicated 모드로 실행 중인데, 웹 서비스는 global 모드로<br>
실행 중이라고 나온다. global 모드로 동작하는 서비스는 한 노드에 레플리카를 하나만 실행한다. 이모드는 인그레스 네트워크를 우회하기 위한 목적으로 사용하는데 리버스 프록시 같은 상황에서 유용하게 사용할 수 있는 모드다.<br>
인그레스 네트워크 : 인그레스 네트워크는 클러스터 외부에서 들어오는 트래픽을 내부 서비스로 라우팅하는 데 사용되는 네트워크로, Docker Swarm과 Kubernetes와 같은 컨테이너 오케스트레이션 도구에서 중요한 역할을 합니다.<br>
리버스 프록시 : 리버스 프록시는 클라이언트의 요청이 직접 원본 서버로 전달되는 대신, 먼저 프록시 서버로 전달된 후 프록시 서버가 해당 요청을 처리하거나 원본 서버로 전달합니다. 그 후, 원본 서버로부터 받은 응답을 다시 클라이언트에게 전달합니다.<br>
<br>
롤링 업데이트 과정에서 replicated 모드와 차이를 보여주기 위한 목적으로 사용했다. 웹 서비스에 대한 설정은 예제 14-1과 같다.(prod.yml에서 발췌)
<br>

![image](https://github.com/user-attachments/assets/84fc6507-c3f6-4183-88f0-f045bcf741e1)

<br>
이 설정에서 서비스를 global 모드로 설정하는 부분은 다음 두 필드다.<br>
<ul>
  <li>mode: global: deploy 항목에 이 필드 설정을 추가하면 해당 서비스는 한 노드에서 한 개의 컨테이너만 실행 된다. 레플리카의 수는 노드의 수와 같으므로 클러스터에 새로 추가된 노드에서 컨테이너가 실행된다.</li>
  <li>mode: host: ports 항목에 이 필드 설정을 추가하면 해당 서비스를 인그레스 네트워크 대신 호스트의 80번 포트와 연결한다. 한 노드에 레플리카 하나만으로도 무방한 가벼운 웹 애플리케이션이거나 네트워크 성능이 매우 중요해서 인그레스 네트워크 내 라우팅에 따른 오버헤드를 제거하고 싶다면 유용하게 사용할 수 있는 패턴이다.</li>
</ul>

<br>

[실습] 이제 버전 v2 컴포즈 파일과 헬스 체크 설정이 추가된 오버라이드 파일, 운영환경용 어버라이드 파일을 병합해 보자. 그리고 스택을 다시 배포하라.<br>

> 헬스 체크, 운영환경 설정 오버라이드 파일과 v2 버전 파일을 병합한다.<br>
> docker-compose -f ./numbers/docker-compose.yml -f ./numvers/prod.yml -f ./numbers/prod-healthcheck.yml -f ./numbers/v2.yml --log-level ERROR config > stack.yml<br>
> 스택을 업데이트 한다.<br>
> docker stack deploy -c stack.yml numbers<br>
> 스택의 레플리카 상태를 확인한다.<br>
> docker stack ps numbers<br>

<br>

![image](https://github.com/user-attachments/assets/f78c7436-435f-4515-af3d-1e55da21debb)

<br>

# 14.2 운영 환경을 위한 롤링 업데이트 설정하기

조금 전의 버전 v2 업데이트에는 기본 설정의 롤링 업데이트를 그대로 사용했지만, API 서비스는 앞으로 좀 더 빠르고 안전하게 업데이트 해야겠다는 생각이 들었다.<br>
롤링 업데이트의 세세한 방식은 컴포즈 파일 내 서비스 정의의 deploy 항목에서 설정할 수 있다. 예제 14-2는 API 서비스에 적용할 update_config 항목이다(prod-update-config.yml 파일에서 발췌).<br>
<br>

![image](https://github.com/user-attachments/assets/89af37f8-d74e-489e-a9b9-540b903663fd)

<br>
update_config 항목의 다음 네가지 프로퍼티를 통해 롤링 업데이트 과정을 원하는 대로 설정할 수 있다.<br>
<ul>
      <li>
            parallelism: 한 번에 교체하는 레플리카의 수를 의미한다. 기본값은 1 이므로 한 번에 레플리카가 하나씩 교체된다.<br>
            앞의 설정에서는 롤링 업데이트를 좀 더 빨리 진행하고 이상을 더 잘 발견할 수 있도록 한 번에 세 대의 컨테이너를 교체하게 했다.
      </li>
      <li>
            monitor: 다음 컨테이너 교체로 넘어가기 전에 새로 실행한 컨테이너의 이상 여부를 모니터링하는 시간을 의미한다.<br>
            기본값은 0이므로 헬스 체크 설정을 포함한 이미지의 경우 이 설정값을 늘려야 한다. 이 시간을 증가시키면 롤링 업데이트의 신뢰성이 증가한다.
      </li>
      <li>
            failure_action: monitor에 설정한 시간 이내에 헬스 체크가 실패하거나 컨테이너가 실행되지 않아 롤링 업데이트가 실패한 경우에 어떤 조치를 취해야 하는지를 의미한다.<br>
            기본값은 업데이트 중이지만, 여기서는 이전 버전으로 롤백하도록 설정했다.
      </li>
      <li>
            order: 레플리카를 교체하는 절차의 순서를 의미한다. stop-first가 기본값으로, 실행중인 레플리카 수가 서비스 정의에 지정된 숫자를 넘어서지 않는다.<br>
            하지만  레플리카를 실행할 수 있는 추가적인 시스템 자원이 있다면 start-first를 선택해 기존 레플리카를 제거하기 전에 새 레플리카를 먼저 검증하도록 하는 것이 좋다.
      </li>
</ul>

parallelism은 전체 레플리카 수의 30%가 적합, monitor는 헬스 체크가 두세번 이상 진행될 수 있을 만큼 넉넉한 시간을 지정하는 것이 좋다. 그래야 이번 레플리카 교체가 완전히 끝난 후 다음 레플리카 교체로 들어갈 수 있다.<br>

[실습] 이번 배포에는 변경된 업데이트 설정과 서비스에 사용된 이미지 태그를 v3로 교체해 반영한다. 롤링 업데이트에 새로 변경된 설정이 적용된다.<br>

> docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml -f ./numbers/prod-healthcheck.yml -f ./numbers/prod-updateconfig.yml -f ./numbers/v3.yml --log-level ERROR config > stack.yml<br>
> docker stack deploy -c stack.yml numbers<br>
> docker stack ps numbers<br>

<br>

![image](https://github.com/user-attachments/assets/1a6e6d53-7653-415e-8adc-e663511f8792)

<br>
스웜의 서비스 정보에서 서비스 정의, 업데이트 설정, 최근 업데이트 결과 등을 좀 더 쉽게 구분할 수 있는 집이 있다.<br>
inspect 명령에서 pretty 플르그를 적용하면 된다. 그러면 스택에서 생성된 서비스가 {stack_name}_{service_name}과 같은 형식으로 명명된다.<br>

[실습] 무작위 숫자 API 서비스의 정보에서 현재 업데이트 상태를 확인하라.<br>
<br>

> docker service inspect --pretty numbers_numbers-api<br>

<br>

![image](https://github.com/user-attachments/assets/e9ab533c-81e3-43ad-a3d5-b8c5861768f9)

<br>

# 14.3 서비스 롤캑 설정하기

docker stack rollback 명령이 따로 있지 않다. 이전상태로 되돌리는 것은 서비스 단위로 이뤄진다.<br>
애플리케이션 배포는 서비스 중단 시간의 주요 원인이다. 모든 업데이트 과정이 자동화돼 있더라도 이 자동화 스크립트와 애플리케이션 정의를 작성하는 것은 여전히 사람이기 때문이다.<br>
사람은 실수를 하게 마련이다. 새 버전을 배포해야 하는데, 누락되면 API서비스가 즉시 오류를 일으키는 중요한 설정이 빠진 상태다.<br>
<br>

[실습] 무작위 숫자 애플리케이션의 버전 v5를 실행하라(v4는 앞서 11장에서 지속적 통합을 체험하기 위해 사용했던 버전이다. 하지만 코드는 버전 v3과 같았다).<br>
      이번 배포는 버전 v5에서 꼭 필요한 설정이 컴포즈 파일에서 누락됐기 때문에 실패할 것이다.<br>

> 코어 컴포즈 파일과 여러 개의 오버라이드 파일을 병합<br>
> docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml ./numbers/prod-healthcheck.yml -f ./numbers/prod-updateconfig.yml -f ./numbers/v5-bad.yml config > stack.yml<br>
> 업데이트 배포<br>
> docker stack deploy -c stack.yml numbers<br>
> 1분간 기다린 후 서비스 상태를 확인<br>
> docker service inspect --pretty numbers_numbers-api<br>

<br>
이상황은 전형적인 배포 실패 사례다. 새 버전의 API 레플리카가 정상적으로 생성되고 시작됐지만, 헬스 체크 과정에서 오류를 일으켰다.<br>
<br>

![image](https://github.com/user-attachments/assets/1a254528-8540-4260-892a-6be259d5b69b)

<br>
이번 배포에서 롤백 설정에 기본값이 사용됐다. 롤백 설정의 기본값은 업데이트와 마찬가지로 한번에 한 테스트씩 stop-first 방식으로 교체하고, 모니터링 시간은 0이며, 교체된 레플리카가 헬스 체크에 실패할 경우 업데이트를 중단하는 것이다.<br>
배포중 오류가 나면 신속하게 이전 상태로 돌아가는 것이 낫다. 예제 14-3은 서비스의 롤백 설정이다(prod-rollback-config.yml파일에서 발췌)<br>
<br>

![image](https://github.com/user-attachments/assets/20d63e8f-2d75-4451-a9b8-01b7774b2072)

<br>
이 설정의 목적은 애플리케이션을 가능한 한 빨리 이전 버전으로 롤백하는 것이다. 따라서 동시 교체 레플리카 수를 6으로 지정해 이상 상태에 있는 레플리카를 한 번에 교체하고,<br> 
교체 전략을 start-first를 적용해 기존 레플리카(새버전) 종료를 신경쓰지 않고 먼저 새 레플리카(구 버전)를 실행하도록 한다.<br>
롤백이 실패하더라도 다음 레플리카를 교체할 것이므로 모니터링 시간도 불필요하다. 이설정은 매우 적극적인 롤백 전략, 이전 버전에 문제가 없었고 이 버즌으로 레플리카를 다시 시작하면 역시 문제가 없으리라 가정에 새운 것이다.<br>

[실습] 버전 v5 업데이트를 다시 시도해 보자. 이번에는 롤백 설정을 변경한 상태로 시도한다. 롤링 업데이트는 이번에도 실패하지만, 롤백이 좀 더 빠르게 일어나며 v3 버전 API의 처리 용량이 빠르게 회복된다.<br>

> 병합할 컴포즈 파일이 더 늘어났다<br>
> docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod.yml -f ./numbers/prod-healthcheck.yml -f ./numbers/prod-update-config.yml -f ./numbers/prod-rollback-config.yml -f ./numbers/v5-bad.yml config > stack.yml<br>
> 롤백 설정을 바꿔 업데이트를 재시도 한다.<br>
> docker stack deploy -c stack.yml numbers<br>
> 롤백이 끝날 때까지 기다린 후 서비스 상태를 확인한다.<br>
> docker service inspect --pretty numbers_numbers_api<br>

<br>
이번에는 롤백에 걸리는 시간이 단축됐다. 현재 단일 래플리카 수가 그리 많지 않아 차이가 미미하지만, 큰 규모에는 서비스에서는 이차이를 무시하기 어렵다.
<br>

오버라이드 파일이 많으면 이런 경우에 위험하다. 업데이트 때마다 이들 파일을 빠짐없이 모두 정확한 순서대로 지정해야 하기 때문이다.<br>
대개의 경우 코어 컴포즈 파일 하나와 환경별 오버라이드 파일 하나, 버전을 정의하는 파일 정도가 일반적이며, 한가지 환경의 설정을 굳이 여러 개의 파일로 분할하지는 않는다.<br>
버전 v5의 문제를 수정해 애플리케이션을 정상으로 되돌리는 마지막 업데이트에서 파일을 이런 식으로 구성해 볼 것이다.<br>
<br>
[실습] 버전 v5 업데이트가 실패하고 이전 버전으로 롤백됐다. 개발 팀을 소집해 확인해 보니 중요한 설정 하나가 누락돼 있었다. 어버라이드 파일 v5.yml에 누락된 설정을 추가하고 prod-full.yml 파일에 운영 환경 관련 설정을 모두 모았다.<br> 
이제 버전 v5를 제대로 배포할 준비가 끝났다.<br>

> 일반적인 방식 - 운영 환경용 설정을 모두 prod-full.yml 한 파일에 모음<br>
> docker-compose -f ./numbers/docker-compose.yml -f ./numbers/prod-full.yml -f ./numbers/v5.yml --log-level ERROR config > stack.yml<br>
> 오류가 수정된 버전 v5 배포<br>
> docker stack deploy -c stack.yml numbers<br>
> 잠시 기다린 후 롤링 업데이트 성공을 확인함<br>
> docker service inspect --pretty numbers_numbewrs-api<br>

<br>

![image](https://github.com/user-attachments/assets/cacef166-8b8e-455e-b4fc-86d576831e73)

<br>
드디어 v5를 성공적으로 업데이트 했다. 그림 14-9는 버전 v3부터 v5까지의 업데이트 과정을 정리한 것이다.<br>

![image](https://github.com/user-attachments/assets/ea20b94d-3487-451f-83de-77ec041ac671)

<br>

# 14.4 클러스터의 중단 시간

이번 장의 내용을 실습하려면 둘 이상의 노드를 갖춘 스웜이 필요하다. 온라인 실습 환경으로 play with docker 사용해 보겠다. 웹브라우저에서 https://labs.play-with-docker.com페이지에서 접근한 다음 도커 허브 계정 로그인한다.<br>

[실습] Play with Docker 웹사이트에서 인스턴스 다섯개를 생성하라. 인스턴스를 생성하고 나면 화면 왼쪽의 내비게이션 바에서 인스턴스의 목록을 볼 수 있다. 목록에서 인스턴스를 클릭하면 주 화면에 해당 인스턴스와 연결된 터미널 창이 나타난다.<br>

> node1을 선택하고 해당 인스턴스의 IP 주소로 스웜을 생성한다<br>
> ip=$(hostname -i)<br>
> docker swarm init --advertise-addr $ip<br>
> 스웜에 새로운 워커와 매니저를 추가하기 위한 명령을 출력한다<br>
> docker swarm join-token manager docker swarm join-token worker<br>
> node2와 node3을 선택하고 각각 매니저 노드 추가 명령을 입력한다<br>
> node4와 nodes를 선택하고 각각 워커 노드 추가 명령을 입력한다<br>
> node1로 돌아와 다른 노드가 잘 준비됐는지 확인한다<br>
> docker node ls<br>

<br>

![image](https://github.com/user-attachments/assets/10842919-b219-44f3-9f5f-030a78cb3042)

<br>
사례하나를 재현해보자. 노드 중 한 대가 운영체제 업데이트 혹은 인프라 작업 등으로 인해 사용할 수 없게 됐다.<br>
이 노드에는 실행 중인 컨테이너가 있을 수도 있어서 이 컨테이너를 안전하게 종료시키고 다른 노드에서 실행한 컨테이너로 교체하고 싶다.<br>
그리고 해당 노드는 유지 보수 모드로 전환해 다음 재부팅 주기가 도래하기 전까지는 이 노드에서 컨테이너를 실행하지 않으려고 한다. 스웜에서는 이 노드의 '유지 보수' 모드를 드레인 모드라고 한다.<br>
메니저노드와 워커 노드 모두 드레인 모드로 설정할 수 있다.<br>

[실습] node1 노드의 터미널 화면에서 다른 두 노드를 드레인 모드로 설정하라.<br>
<br>

> docker node update --availability drain node5<br>
> docker node update --availability drain node3<br>
> 각 노드의 상태를 확인한다<br>
> docker node ls<br>

<br>

![image](https://github.com/user-attachments/assets/ef203461-ec19-4922-b7a0-62dfc2cc4611)

<br>
워커 노드와 메니저 노드의 드레인 모드는 조금 차이가 있다. <br>
두가지 모두 현재 실행 중인 레플리카가 종료되고 새로운 레플리카를 실행하지도 않는다는 점은 같지만,<br>
메니저 노드는 드레인 모드가 돼고 계속 클러스터의 관리 그룹으로 기능하며 클러스터 데이터베이스 동기화 및 관리 API 제공도 계속하고 메니저 노드 중 리더인 리더 메니저가 될 수도 있다.<br>
그림 14-11은 두개의 노드가 드레인 모드로 들어간 클러스터의 상태 정보를 출력한 것이다.<br>
<br>

![image](https://github.com/user-attachments/assets/8f21d5c0-d4d6-448f-9bb8-648aa23f9530)

<br>











# 14.5 스웜 클러스터의 고가용성





















# 14.6 연습문제
